{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDataset = pd.read_csv(\"data/MovieGenre.csv\", sep=\",\", encoding = \"ISO-8859-1\")\n",
    "overallDataset = overallDataset[[\"imdbId\", \"Genre\"]]\n",
    "# We need to drop NaNs\n",
    "overallDataset = overallDataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114709</td>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113497</td>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113228</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114885</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113041</td>\n",
       "      <td>Comedy|Family|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40103</th>\n",
       "      <td>83168</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40104</th>\n",
       "      <td>82875</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40105</th>\n",
       "      <td>815258</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40106</th>\n",
       "      <td>79142</td>\n",
       "      <td>Action|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40107</th>\n",
       "      <td>70710</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39963 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       imdbId                       Genre\n",
       "0      114709  Animation|Adventure|Comedy\n",
       "1      113497     Action|Adventure|Family\n",
       "2      113228              Comedy|Romance\n",
       "3      114885        Comedy|Drama|Romance\n",
       "4      113041       Comedy|Family|Romance\n",
       "...       ...                         ...\n",
       "40103   83168                       Drama\n",
       "40104   82875                      Comedy\n",
       "40105  815258                      Horror\n",
       "40106   79142               Action|Comedy\n",
       "40107   70710        Crime|Drama|Thriller\n",
       "\n",
       "[39963 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overallDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out zero byte images, we had 39963 records\n",
      "Now we have 39137 records\n",
      "We have removed 826 records\n"
     ]
    }
   ],
   "source": [
    "# We need to filter overallDataset\n",
    "# For when imdbId is not in the list of 0 byte images\n",
    "f = open(\"0byte_images.txt\", \"r\")\n",
    "zero_byte_images = f.read()\n",
    "zero_byte_images = zero_byte_images.split(\"\\n\")\n",
    "zero_byte_images = list(filter(None, zero_byte_images))\n",
    "for i in range(len(zero_byte_images)):\n",
    "    process_record = zero_byte_images[i].replace(\"posters/\", \"\").replace(\".jpg\", \"\")\n",
    "    if process_record == \"\":\n",
    "        print(zero_byte_images[i])\n",
    "    zero_byte_images[i] = int(process_record)\n",
    "    \n",
    "# Read in bad_jpegs\n",
    "f = open(\"bad_jpegs.txt\", \"r\")\n",
    "bad_jpegs = f.read()\n",
    "bad_jpegs = bad_jpegs.split(\"\\n\")\n",
    "bad_jpegs = list(filter(None, bad_jpegs))\n",
    "for i in range(len(bad_jpegs)):\n",
    "    bad_jpegs[i] = int(bad_jpegs[i])\n",
    "    \n",
    "remove_images = zero_byte_images + bad_jpegs\n",
    "\n",
    "before_length = len(overallDataset)\n",
    "print(\"Before filtering out zero byte images, we had \" + str(before_length) + \" records\")\n",
    "overallDataset = overallDataset[~overallDataset['imdbId'].isin(remove_images)]\n",
    "print(\"Now we have \" + str(len(overallDataset)) + \" records\")\n",
    "print(\"We have removed \" + str(before_length - len(overallDataset)) + \" records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_discover(genre):\n",
    "    category = None\n",
    "    if \"|\" in genre:\n",
    "        genre_split = genre.split(\"|\")\n",
    "        if (genre_split[0] == \"Drama\") or (genre_split[0] == \"Comedy\") or (genre_split[0] == \"Action\"):\n",
    "            if (genre_split[1] == \"Drama\"):\n",
    "                if len(genre_split) == 3:\n",
    "                    category = genre_split[2]\n",
    "                else:\n",
    "                    category = genre_split[1]\n",
    "            else:\n",
    "                category = genre_split[1]\n",
    "        else:\n",
    "            category = genre_split[0]\n",
    "    else:\n",
    "        category = genre\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Records originally: 39137\n",
      "Number of unique values in Genre_1 originally: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75568/388279227.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  overallDataset['Genre_1'] = overallDataset.apply(lambda x: genre_discover(x['Genre']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "overallDataset['Genre_1'] = overallDataset.apply(lambda x: genre_discover(x['Genre']), axis=1)\n",
    "print(\"Number of Records originally: \" + str(len(overallDataset[\"Genre_1\"])))\n",
    "print(\"Number of unique values in Genre_1 originally: \" + str(len(overallDataset[\"Genre_1\"].unique())))\n",
    "#overallDataset[\"Genre_1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = overallDataset[\"Genre_1\"].value_counts()\n",
    "filt_genre_counts = genre_counts[genre_counts >= 1100].index\n",
    "fixedOverallDataset = overallDataset[overallDataset['Genre_1'].isin(filt_genre_counts)]\n",
    "\n",
    "new_balanced_df = pd.DataFrame(columns=[\"imdbId\", \"Genre\", \"Genre_1\"])\n",
    "for genre in filt_genre_counts:\n",
    "    cut_temp_df = fixedOverallDataset[fixedOverallDataset[\"Genre_1\"] == genre].iloc[:1200]\n",
    "    new_balanced_df = pd.concat([new_balanced_df, cut_temp_df])\n",
    "    \n",
    "genre_category_numbers = list(filt_genre_counts)\n",
    "def label_id_add(genre):\n",
    "    return int(genre_category_numbers.index(genre))\n",
    "\n",
    "    \n",
    "new_balanced_df = new_balanced_df.drop(['Genre'], axis=1)\n",
    "new_balanced_df = new_balanced_df.rename(columns={\"Genre_1\": \"Genre\"})\n",
    "new_balanced_df['Label'] = new_balanced_df.apply(lambda x: label_id_add(x['Genre']), axis=1)\n",
    "new_balanced_df = new_balanced_df.drop(['Genre'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1200\n",
       "1    1200\n",
       "2    1200\n",
       "3    1200\n",
       "4    1200\n",
       "5    1200\n",
       "6    1200\n",
       "7    1200\n",
       "8    1200\n",
       "9    1200\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_balanced_df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new number of records was 12000.\n",
      "The train size was 10800 and the test size was 1200\n",
      "Number of unique values Labels: 10\n",
      "The columns we save out are: ['imdbId', 'Label']\n"
     ]
    }
   ],
   "source": [
    "original_size = len(new_balanced_df)\n",
    "train, test = train_test_split(new_balanced_df, test_size=0.1)\n",
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "\n",
    "print(\"The new number of records was \" + str(original_size) + \".\")\n",
    "print(\"The train size was \" + str(train_size) + \" and the test size was \" + str(test_size))\n",
    "print(\"Number of unique values Labels: \" + str(len(new_balanced_df[\"Label\"].unique())))\n",
    "print(\"The columns we save out are: \" + str(list(new_balanced_df.columns)))\n",
    "assert original_size == (train_size + test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test_labels.csv\", index=False, header=False)\n",
    "train.to_csv(\"train_labels.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
